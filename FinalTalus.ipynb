{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmj+edND2jPDHBTya5VlgH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SriramRajagopal42/YosemiteTalusProj/blob/main/FinalTalus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUUGKBv7JABg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5944e6a0-a206-4cee-a11f-352b4bd1bc97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Purpose: Import data stored in Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Purpose: Imports\n",
        "\n",
        "import os\n",
        "\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "\n",
        "import PIL\n",
        "from PIL import ImageOps\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import gdal\n",
        "from gdalconst import *"
      ],
      "metadata": {
        "id": "E68eqTx4lsnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Purpose: Basic Info\n",
        "\n",
        "img_size = (256, 256)\n",
        "num_classes = 2\n",
        "num_channels = 6\n",
        "batch_size = 2\n",
        "\n",
        "satellite_file = '/content/drive/MyDrive/Yosemite/KingsCanyon_Satellite.tif' #Enter your Satellite tif file path\n",
        "dem_file = '/content/drive/MyDrive/Yosemite/KingsCanyon_DEM_WGS.tif' #Enter your DEM tif file path\n",
        "slope_file = '/content/drive/MyDrive/Yosemite/KingsCanyon_Slope.tif' #Enter your Slope tif file path\n",
        "aspect_file = '/content/drive/MyDrive/Yosemite/KingsCanyon_Aspect.tif' #Enter your Aspect tif file path\n",
        "\n",
        "input_dir = '/content/drive/MyDrive/MegaNumpy' #Enter your empty Input Folder directory\n",
        "satellite_dir = '/content/drive/MyDrive/Chunks/SatelliteChunks' #Enter your empty Satellite Chunks Folder directory\n",
        "dem_dir = '/content/drive/MyDrive/Chunks/KingsCanyonChunks' #Enter your empty DEM Chunks Folder directory\n",
        "slope_dir = '/content/drive/MyDrive/Chunks/SlopeChunks' #Enter your empty Slope Chunks Folder directory\n",
        "aspect_dir = '/content/drive/MyDrive/Chunks/AspectChunks' #Enter your empty Aspect Chunks Folder directory\n",
        "\n",
        "output_dir = '/content/drive/MyDrive/Chunks/TalusChunks' #Enter your Output Folder directory (want to remove this)\n",
        "model_dir = '/content/model.h5' #Enter your model directory"
      ],
      "metadata": {
        "id": "1e2wbuGQR2K-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Purpose: Turn all of the data into chunks, then add those chunks together and turn them into arrays\n",
        "\n",
        "width = 3675\n",
        "height = 1847\n",
        "tilesize = 256\n",
        "\n",
        "for i in range(0, width, tilesize):\n",
        "    for j in range(0, height, tilesize):\n",
        "        gdaltranString = \"gdal_translate -of GTIFF -srcwin \"+str(i)+\", \"+str(j)+\", \"+str(tilesize)+\", \" \\\n",
        "            +str(tilesize)+\" \" + satellite_dir + \" SatelliteChunk_\"+str(i)+\"_\"+str(j)+\".tif\"\n",
        "        os.system(gdaltranString)\n",
        "!mv SatelliteChunk* /content/drive/MyDrive/Chunks/SatelliteChunks #Enter your empty Satellite Chunks Folder directory (no quotation marks)\n",
        "\n",
        "for i in range(0, width, tilesize):\n",
        "    for j in range(0, height, tilesize):\n",
        "        gdaltranString = \"gdal_translate -of GTIFF -srcwin \"+str(i)+\", \"+str(j)+\", \"+str(tilesize)+\", \" \\\n",
        "            +str(tilesize)+\" \" + dem_dir + \" DEMChunk_\"+str(i)+\"_\"+str(j)+\".tif\"\n",
        "        os.system(gdaltranString)\n",
        "!mv DEMChunk* /content/drive/MyDrive/Chunks/KingsCanyonChunks #Enter your empty DEM Chunks Folder directory (no quotation marks)\n",
        "\n",
        "for i in range(0, width, tilesize):\n",
        "    for j in range(0, height, tilesize):\n",
        "        gdaltranString = \"gdal_translate -of GTIFF -srcwin \"+str(i)+\", \"+str(j)+\", \"+str(tilesize)+\", \" \\\n",
        "            +str(tilesize)+\" \" + slope_dir + \" SlopeChunk_\"+str(i)+\"_\"+str(j)+\".tif\"\n",
        "        os.system(gdaltranString)\n",
        "!mv SlopeChunk* /content/drive/MyDrive/Chunks/SlopeChunks #Enter your empty Slope Chunks Folder directory (no quotation marks)\n",
        "\n",
        "for i in range(0, width, tilesize):\n",
        "    for j in range(0, height, tilesize):\n",
        "        gdaltranString = \"gdal_translate -of GTIFF -srcwin \"+str(i)+\", \"+str(j)+\", \"+str(tilesize)+\", \" \\\n",
        "            +str(tilesize)+\" \" + aspect_dir + \" AspectChunk_\"+str(i)+\"_\"+str(j)+\".tif\"\n",
        "        os.system(gdaltranString)\n",
        "!mv AspectChunk* /content/drive/MyDrive/Chunks/AspectChunks #Enter your empty Aspect Chunks Folder directory (no quotation marks)\n",
        "\n",
        "#---------------------------------------------------------------------------------\n",
        "\n",
        "def create_megachunk(rgb_paths, elevation_paths, slope_paths, aspect_paths):\n",
        "    for f_rgb, f_ele, f_slope, f_aspect in zip(rgb_paths, elevation_paths, slope_paths, aspect_paths):\n",
        "        rgb_array = np.array(load_img(f_rgb))\n",
        "        r = rgb_array[..., 0]\n",
        "        g = rgb_array[..., 1]\n",
        "        b = rgb_array[..., 2]\n",
        "\n",
        "        elevation = np.array(load_img(f_ele))\n",
        "        elevation = elevation[..., 0]\n",
        "\n",
        "        slope = np.array(load_img(f_slope))\n",
        "        slope = slope[..., 0]\n",
        "\n",
        "        aspect = np.array(load_img(f_aspect))\n",
        "        aspect = aspect[..., 0]\n",
        "\n",
        "        megachunk =  np.stack([r, g, b, elevation, slope, aspect], axis=-1)\n",
        "        i_index, j_index = f_rgb.split(\".\")[0].split(\"_\")[1:]\n",
        "        np.save(\"megachunk_{}_{}.npy\".format(i_index, j_index), megachunk)\n",
        "\n",
        "#--------------------------------------------------------------------------------\n",
        "\n",
        "rgbpth = sorted(\n",
        "            [\n",
        "                os.path.join(str(satellite_dir), fname)\n",
        "                for fname in os.listdir(str(satellite_dir))\n",
        "            ]\n",
        "        )\n",
        "\n",
        "dempth = sorted(\n",
        "            [\n",
        "                os.path.join(str(dem_dir), fname)\n",
        "                for fname in os.listdir(str(dem_dir))\n",
        "            ]\n",
        "        )\n",
        "\n",
        "slopepth = sorted(\n",
        "            [\n",
        "                os.path.join(str(slope_dir), fname)\n",
        "                for fname in os.listdir(str(slope_dir))\n",
        "            ]\n",
        "        )\n",
        "\n",
        "aspectpth = sorted(\n",
        "            [\n",
        "                os.path.join(str(aspect_dir), fname)\n",
        "                for fname in os.listdir(str(aspect_dir))\n",
        "            ]\n",
        "        )\n",
        "\n",
        "\n",
        "create_megachunk(rgbpth, dempth, slopepth, aspectpth)\n",
        "\n",
        "!mv megachunk* /content/drive/MyDrive/MegaNumpy #Enter your empty Input Folder directory (no quotation marks)"
      ],
      "metadata": {
        "id": "P5GunZh8A7bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Purpose: Helper to iterate over the data (as Numpy arrays)\n",
        "\n",
        "class TalusIdentifier(keras.utils.Sequence):\n",
        "\n",
        "    def __init__(self, batch_size, img_size, input_img_paths, target_img_paths, channels):\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.input_img_paths = input_img_paths\n",
        "        self.target_img_paths = target_img_paths\n",
        "        self.channels = channels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.target_img_paths) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        i = idx * self.batch_size\n",
        "        batch_input_img_paths = self.input_img_paths[i : i + self.batch_size]\n",
        "        batch_target_img_paths = self.target_img_paths[i : i + self.batch_size]\n",
        "        x = np.zeros((self.batch_size,) + self.img_size + (6,), dtype=\"uint8\")\n",
        "        for j, path in enumerate(batch_input_img_paths):\n",
        "            img = np.load(path)\n",
        "            x[j] = img\n",
        "        y = np.zeros((self.batch_size,) + self.img_size + (1,), dtype=\"uint8\")\n",
        "        for j, path in enumerate(batch_target_img_paths):\n",
        "            img = np.array(load_img(path))[..., 0]\n",
        "            y[j] = (np.expand_dims(img, 2) / 255.0).astype(np.uint8)\n",
        "        \n",
        "        return x, y\n"
      ],
      "metadata": {
        "id": "OrdGxg8Ckykk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Purpose: Split Data into training/validation\n",
        "\n",
        "input_pths = sorted(\n",
        "    [\n",
        "        os.path.join(input_dir, fname)\n",
        "        for fname in os.listdir(input_dir)\n",
        "    ]\n",
        ")\n",
        "\n",
        "target_img_paths = sorted(\n",
        "    [\n",
        "        os.path.join(output_dir, fname)\n",
        "        for fname in os.listdir(output_dir)\n",
        "    ]\n",
        ")\n",
        "\n",
        "input_pths, target_img_paths = shuffle(input_pths, target_img_paths)\n",
        "\n",
        "val_samples = 10\n",
        "\n",
        "train_input_img_paths = input_pths[:-val_samples]\n",
        "train_target_img_paths = target_img_paths[:-val_samples]\n",
        "val_input_img_paths = input_pths[-val_samples:]\n",
        "val_target_img_paths = target_img_paths[-val_samples:]\n",
        "\n",
        "train_gen = TalusIdentifier(\n",
        "    batch_size, img_size, train_input_img_paths, train_target_img_paths, num_channels\n",
        ")\n",
        "\n",
        "val_gen = TalusIdentifier(batch_size, img_size, val_input_img_paths, val_target_img_paths, num_channels)"
      ],
      "metadata": {
        "id": "0gSw7plNlYYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Purpose: Generate predictions for all images in the validation set\n",
        "\n",
        "new_model = tf.keras.models.load_model(model_dir)\n",
        "\n",
        "val_preds = new_model.predict(input_pths)\n",
        "\n",
        "def display_mask(i):\n",
        "    mask = np.argmax(val_preds[i], axis=-1)\n",
        "    mask = np.expand_dims(mask, axis=-1)\n",
        "    img = PIL.ImageOps.autocontrast(keras.preprocessing.image.array_to_img(mask))\n",
        "    display(img)\n",
        "\n",
        "i = 9 # Choose a number from 0-9 and re-run the cell to get a different test image\n",
        "\n",
        "img = PIL.ImageOps.autocontrast(load_img(val_target_img_paths[i]))\n",
        "pred_binary = np.argmax(val_preds[i], axis=-1)\n",
        "display(img)\n",
        "\n",
        "display_mask(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "id": "J9bPbjHMllek",
        "outputId": "51917c9b-f624-4bbc-82a6-90f49c60ce60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 256, 256, 6) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256, 256, 6), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (None,).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-1ea4d45e79c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#val_gen = TalusIdentifier(batch_size, img_size, input_pths, num_channels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mval_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_pths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdisplay_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 228, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"model\" (type Functional).\n    \n    Input 0 of layer \"conv2d\" is incompatible with the layer: expected min_ndim=4, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None,), dtype=string)\n      • training=False\n      • mask=None\n"
          ]
        }
      ]
    }
  ]
}