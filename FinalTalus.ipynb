{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SUUGKBv7JABg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "399ebf0c-e57e-4446-b1c1-d318162e3466"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#Import data stored in Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Imports\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "import PIL\n",
        "from PIL import ImageOps\n",
        "from sklearn.utils import shuffle"
      ],
      "metadata": {
        "id": "E68eqTx4lsnE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Basic Info\n",
        "\n",
        "img_size = (256, 256)\n",
        "num_classes = 2\n",
        "num_channels = 6\n",
        "batch_size = 2\n",
        "\n",
        "input_dir = '/content/drive/MyDrive/MegaNumpy' #Enter your Input Folder directory\n",
        "output_dir = '/content/drive/MyDrive/Chunks/TalusChunks' #Enter your Output Folder directory\n",
        "model_dir = '/content/perfecttalus.h5' #Enter your model directory"
      ],
      "metadata": {
        "id": "1e2wbuGQR2K-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Helper to iterate over the data (as Numpy arrays)\n",
        "\n",
        "class TalusIdentifier(keras.utils.Sequence):\n",
        "\n",
        "    def __init__(self, batch_size, img_size, input_img_paths, target_img_paths, channels):\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.input_img_paths = input_img_paths\n",
        "        self.target_img_paths = target_img_paths\n",
        "        self.channels = channels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.target_img_paths) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        i = idx * self.batch_size\n",
        "        batch_input_img_paths = self.input_img_paths[i : i + self.batch_size]\n",
        "        batch_target_img_paths = self.target_img_paths[i : i + self.batch_size]\n",
        "        x = np.zeros((self.batch_size,) + self.img_size + (6,), dtype=\"uint8\")\n",
        "        for j, path in enumerate(batch_input_img_paths):\n",
        "            img = np.load(path)\n",
        "            x[j] = img\n",
        "        y = np.zeros((self.batch_size,) + self.img_size + (1,), dtype=\"uint8\")\n",
        "        for j, path in enumerate(batch_target_img_paths):\n",
        "            img = np.array(load_img(path))[..., 0]\n",
        "            y[j] = (np.expand_dims(img, 2) / 255.0).astype(np.uint8)\n",
        "        \n",
        "        return x, y\n"
      ],
      "metadata": {
        "id": "OrdGxg8Ckykk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split Data into training/validation\n",
        "\n",
        "input_pths = sorted(\n",
        "    [\n",
        "        os.path.join(input_dir, fname)\n",
        "        for fname in os.listdir(input_dir)\n",
        "    ]\n",
        ")\n",
        "\n",
        "target_img_paths = sorted(\n",
        "    [\n",
        "        os.path.join(output_dir, fname)\n",
        "        for fname in os.listdir(output_dir)\n",
        "    ]\n",
        ")\n",
        "\n",
        "input_pths, target_img_paths = shuffle(input_pths, target_img_paths)\n",
        "\n",
        "# Split our img paths into a training and a validation set\n",
        "val_samples = 10\n",
        "\n",
        "train_input_img_paths = input_pths[:-val_samples]\n",
        "train_target_img_paths = target_img_paths[:-val_samples]\n",
        "val_input_img_paths = input_pths[-val_samples:]\n",
        "val_target_img_paths = target_img_paths[-val_samples:]\n",
        "\n",
        "# Instantiate data Sequences for each split\n",
        "train_gen = TalusIdentifier(\n",
        "    batch_size, img_size, train_input_img_paths, train_target_img_paths, num_channels\n",
        ")\n",
        "\n",
        "val_gen = TalusIdentifier(batch_size, img_size, val_input_img_paths, val_target_img_paths, num_channels)"
      ],
      "metadata": {
        "id": "0gSw7plNlYYV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions for all images in the validation set\n",
        "\n",
        "new_model = tf.keras.models.load_model(model_dir)\n",
        "\n",
        "val_gen = TalusIdentifier(batch_size, img_size, val_input_img_paths, val_target_img_paths, num_channels)\n",
        "val_preds = new_model.predict(val_gen)\n",
        "\n",
        "def display_mask(i):\n",
        "    \"\"\"Quick utility to display a model's prediction.\"\"\"\n",
        "    mask = np.argmax(val_preds[i], axis=-1)\n",
        "    mask = np.expand_dims(mask, axis=-1)\n",
        "    img = PIL.ImageOps.autocontrast(keras.preprocessing.image.array_to_img(mask))\n",
        "    display(img)\n",
        "\n",
        "# Display results for validation image #10\n",
        "i = 9 # Choose a number from 0-9 and re-run the cell to get a different test image\n",
        "\n",
        "# Display ground-truth target mask\n",
        "img = PIL.ImageOps.autocontrast(load_img(val_target_img_paths[i]))\n",
        "pred_binary = np.argmax(val_preds[i], axis=-1)\n",
        "display(img)\n",
        "\n",
        "# Display mask predicted by our model\n",
        "display_mask(i)  # Note that the model only sees inputs at 150x150."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "J9bPbjHMllek",
        "outputId": "0c66df52-9ddb-444c-f0cd-04729398b713"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=256x256 at 0x7FD1FB1007D0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAIAAADTED8xAAAC+ElEQVR4nO3d23ajIBgGUMzq+78yc9E2dbI8gCIg7n0z08k0Nfh/nExqCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALBk+v4jxvjz9TS1Oxio7RVm1f/xdxjeV+L/mwfDKMEwprDU689LfG1MEAMGsByAn8emrUfDUgZijO9/3M4V9GC1WFO/f5qyvlcG6Mr+VKfkD1P9dGanIgumQvXTodf2w6WqVvXTp50AFKH66dZOAFwXY2w1RgApols1AhBkgF7V2wX6+5GWBHSj0ggwZzSgH/vboDpsBpY0AhTPgEGATjSYAkE/9rv263prkyuaa3khzESI5lb74JrVaSiglf8+EqlL5mnOfiCm2HEYBGjhq3npQ0O2QXm0AgE4f7XY/IdWzgbgXbuKmDsqOQWSAW6n8BpABriX8ovgAxmwE0UrpwKwVusywF2cCkDZqo0xigGVdXcdQAyoKe83e64+y8qc58yTW09TQZkAhLR69Wt06U2xKVBKcatpelNyDZAyfZcButJgESwD9KN8AMyFemAzLVGzbdDtDEjIGUo/XcvrAMcuJMdf1xzU7WmZLMW2Qf+esUTnnXhUBooP7mabK/U+wX36Pt/OdNDxHzXC26Gdey1wWKcfiMl9qidXwOJrNyomqvpWiFy5xzbGWf941RsvKuse5iwqswbQ3Nd5V/m8kXe7hhijk5JiCr2+Z/PYUQ1w1nsek8dzfA1w6b0zDhfBAIuBUq06QFNUcDAAl/YuJ8/cACe+YAYGaI1LvUJmc7e6adLTBvSnvd5WMkaAhqWfG9HrDqYmc6EK9jcW6tfT9vX87dM5TPWHCwp3pMYp5ZYt8pD9bwGo4B8ME/ZsvphcAwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=256x256 at 0x7FD1F2955DD0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAAAAAB5Gfe6AAACgElEQVR4nO3c0XKqMBQF0OD4/7+c+yC9Qk0kKIFyWOuh06GM5OyEEBGbEgAAQAT56AYAAAAAAHSw1b3P20avs7+8TQTnDWAjJw5gOLoB/A1fzgVnHkc5pZSGnL6q4rQBzPr9igGkaQZfVHHiq8A2zhzAJqP3zAGkIZ37HN5A9kBEyvnaGWz0nggAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAtpRX7n/v0orDrC0/pVuHVhxq6Lz/n5aD1fOB9acAAAAAAHAtve6iukELnNH1PlkZUkopjxN2fm66jFtKKY+Vj90/GwXhh8RjBDx+qRUbekhMirtk/Q0PSMSufxpAudLg9U8DCD/fFS2eAjl4Ls8Aghda8wygerLHTqblMbnQCTQ9Jxg5gcXLYEopdALTEXDJBFoflQ2bQMN7gcKugVgH/Pxy0fqf9wNa991X7n7MYU3PR5wFwn1hYq1VAUScJyoBDENpvEc8BcpzwOw2+ev2SIojIGCdVSbBwrb/A2C4wFB4DWBWdfwEXgJ4W3LAO6Rrvzo7fooWx0sAV3u4p/JeYJ5BfvO3s6tcBt+VHGseaFsHxOr0mVoAv7o5bgKtK8HJ6iBWGAsLoen2x49dV4c7TDfDigdD8nxb9wvmLlfk+qNB9WPnlp2+t8+aq7oSbDt0v07a62L7ydvhULPgvRJ1e5FdBsF+i63yKbB3H+f5QZ/l9/9c4JN/pNSpe8YUdl5pl64CC6kXWvh1P1Wr7j4C2hdC73zda8fNq+vuCPVzWAK3X8debkinc/SoBB7HzSsa8fOlgmkQ27S+x+Sy6D4eJ687Vo+GHXOj5aMZbzZsPnyV4guXdB4E/wCgHl5+oE4ZUgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4LLRoJoHn7he"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}